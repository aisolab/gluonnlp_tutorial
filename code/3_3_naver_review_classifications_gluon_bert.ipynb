{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "naver_review_classifications_gluon_bert.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvjqOdDgT5zb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "39c3f64c-5e35-45cf-ce44-57032b635e9a"
      },
      "source": [
        "!pip install mxnet-cu100\n",
        "!pip install gluonnlp pandas tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.16.4)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mTNl7BKT2Fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mxnet.gluon import nn, rnn\n",
        "from mxnet import gluon, autograd\n",
        "import gluonnlp as nlp\n",
        "from mxnet import nd \n",
        "import mxnet as mx\n",
        "import time\n",
        "import itertools\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc-zco-ST2F_",
        "colab_type": "text"
      },
      "source": [
        "### 버트 로딩 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89lsydguT2GG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctx = mx.gpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGwX9REiT2Gb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "466d7fad-023f-40f3-8297-b04bdaad1f22"
      },
      "source": [
        "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
        "                                             dataset_name='wiki_multilingual_cased',\n",
        "                                             pretrained=True, ctx=ctx, use_pooler=True,\n",
        "                                             use_decoder=False, use_classifier=False)\n",
        "#print(bert_base)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab file is not found. Downloading.\n",
            "Downloading /root/.mxnet/models/1565856577.1304765wiki_multilingual_cased-0247cb44.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/wiki_multilingual_cased-0247cb44.zip...\n",
            "Downloading /root/.mxnet/models/bert_12_768_12_wiki_multilingual_cased-b0f57a20.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_wiki_multilingual_cased-b0f57a20.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i69AUj9gT2Gk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "f2338ed4-86f1-4118-aeea-cd0d07be15c0"
      },
      "source": [
        "ds = gluon.data.SimpleDataset([['나 보기가 역겨워', '김소월']])\n",
        "\n",
        "tok = nlp.data.BERTTokenizer(vocab=vocabulary, lower=False)\n",
        "\n",
        "trans = nlp.data.BERTSentenceTransform(tok, max_seq_length=10)\n",
        "\n",
        "list(ds.transform(trans))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([    2,  8982,  9356, 47869,  9566,     3,  8935, 22333, 38851,\n",
              "             3], dtype=int32),\n",
              "  array(10, dtype=int32),\n",
              "  array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1], dtype=int32))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qy9g_UMVtdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "outputId": "1c02e06b-94bc-4b9c-c9d2-0a04772f8469"
      },
      "source": [
        "!wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
        "!wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-15 08:13:44--  https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/374ftkec978br3d/ratings_train.txt [following]\n",
            "--2019-08-15 08:13:44--  https://www.dropbox.com/s/dl/374ftkec978br3d/ratings_train.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucef6f352d774589b42c518ef3f0.dl.dropboxusercontent.com/cd/0/get/Amq3zXJvW28FXK4jT8dPnncZI9ibrr6FYx7ZR_SOt-Z5Jt2lsXU9Y7bLGmO0LkPMnZ2eufdoF14xTEuRd-jV11A02AOXHYKmXj_MJPGzEGROAYWCe02sMg0a5Dnj0MkvXMo/file?dl=1# [following]\n",
            "--2019-08-15 08:13:45--  https://ucef6f352d774589b42c518ef3f0.dl.dropboxusercontent.com/cd/0/get/Amq3zXJvW28FXK4jT8dPnncZI9ibrr6FYx7ZR_SOt-Z5Jt2lsXU9Y7bLGmO0LkPMnZ2eufdoF14xTEuRd-jV11A02AOXHYKmXj_MJPGzEGROAYWCe02sMg0a5Dnj0MkvXMo/file?dl=1\n",
            "Resolving ucef6f352d774589b42c518ef3f0.dl.dropboxusercontent.com (ucef6f352d774589b42c518ef3f0.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to ucef6f352d774589b42c518ef3f0.dl.dropboxusercontent.com (ucef6f352d774589b42c518ef3f0.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14628807 (14M) [application/binary]\n",
            "Saving to: ‘ratings_train.txt?dl=1’\n",
            "\n",
            "ratings_train.txt?d 100%[===================>]  13.95M  84.2MB/s    in 0.2s    \n",
            "\n",
            "2019-08-15 08:13:45 (84.2 MB/s) - ‘ratings_train.txt?dl=1’ saved [14628807/14628807]\n",
            "\n",
            "--2019-08-15 08:13:47--  https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/977gbwh542gdy94/ratings_test.txt [following]\n",
            "--2019-08-15 08:13:47--  https://www.dropbox.com/s/dl/977gbwh542gdy94/ratings_test.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucdbdf9608e9f1730a558af5fdfd.dl.dropboxusercontent.com/cd/0/get/Amo8KQEYEkexXaQpzbWDgzoSDijM32HbshuUSzGxyQwKytWsKsv3sS0036wIJ3t8bmVAvElO2q25futhDQAoZWhUZ2IwdfwPJ1SaQUsmsLjC4b6nbEQdT07FBx6woV--b3U/file?dl=1# [following]\n",
            "--2019-08-15 08:13:47--  https://ucdbdf9608e9f1730a558af5fdfd.dl.dropboxusercontent.com/cd/0/get/Amo8KQEYEkexXaQpzbWDgzoSDijM32HbshuUSzGxyQwKytWsKsv3sS0036wIJ3t8bmVAvElO2q25futhDQAoZWhUZ2IwdfwPJ1SaQUsmsLjC4b6nbEQdT07FBx6woV--b3U/file?dl=1\n",
            "Resolving ucdbdf9608e9f1730a558af5fdfd.dl.dropboxusercontent.com (ucdbdf9608e9f1730a558af5fdfd.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to ucdbdf9608e9f1730a558af5fdfd.dl.dropboxusercontent.com (ucdbdf9608e9f1730a558af5fdfd.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893335 (4.7M) [application/binary]\n",
            "Saving to: ‘ratings_test.txt?dl=1’\n",
            "\n",
            "ratings_test.txt?dl 100%[===================>]   4.67M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-08-15 08:13:48 (37.9 MB/s) - ‘ratings_test.txt?dl=1’ saved [4893335/4893335]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LfCTweqT2Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt0raV8uT2G2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTDataset(mx.gluon.data.Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "        sent_dataset = gluon.data.SimpleDataset([[\n",
        "            i[sent_idx],\n",
        "        ] for i in dataset])\n",
        "        self.sentences = sent_dataset.transform(transform)\n",
        "        self.labels = gluon.data.SimpleDataset(\n",
        "            [np.array(np.int32(i[label_idx])) for i in dataset])\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtk-8pQST2G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=False)\n",
        "max_len = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K_BLZP_T2HF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, bert_tokenizer, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, bert_tokenizer, max_len, True, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhaw0H4ST2HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTClassifier(nn.Block):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 num_classes=2,\n",
        "                 dropout=None,\n",
        "                 prefix=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n",
        "        self.bert = bert\n",
        "        with self.name_scope():\n",
        "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
        "            if dropout:\n",
        "                self.classifier.add(nn.Dropout(rate=dropout))\n",
        "            self.classifier.add(nn.Dense(units=num_classes))\n",
        "\n",
        "    def forward(self, inputs, token_types, valid_length=None):\n",
        "        _, pooler = self.bert(inputs, token_types, valid_length)\n",
        "        return self.classifier(pooler)\n",
        "                                           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y00BOPwST2HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTClassifier(bert_base, num_classes=2, dropout=0.3)\n",
        "# 분류 레이어만 초기화 한다. \n",
        "model.classifier.initialize(ctx=ctx)\n",
        "model.hybridize()\n",
        "\n",
        "# softmax cross entropy loss for classification\n",
        "loss_function = gluon.loss.SoftmaxCELoss()\n",
        "\n",
        "metric = mx.metric.Accuracy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2dLhnHkT2Hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "lr = 5e-5\n",
        "\n",
        "train_dataloader = mx.gluon.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=int(batch_size/2), num_workers=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESo76UH-T2Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = gluon.Trainer(model.collect_params(), 'bertadam',\n",
        "                        {'learning_rate': lr, 'epsilon': 1e-9, 'wd':0.01})\n",
        "\n",
        "log_interval = 4\n",
        "num_epochs = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wspMBDOAT2H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LayerNorm과 Bias에는 Weight Decay를 적용하지 않는다. \n",
        "for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n",
        "    v.wd_mult = 0.0\n",
        "params = [\n",
        "    p for p in model.collect_params().values() if p.grad_req != 'null'\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCR6AMKHT2H6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_accuracy(model, data_iter, ctx=ctx):\n",
        "    acc = mx.metric.Accuracy()\n",
        "    i = 0\n",
        "    for i, (t,v,s, label) in enumerate(data_iter):\n",
        "        token_ids = t.as_in_context(ctx)\n",
        "        valid_length = v.as_in_context(ctx)\n",
        "        segment_ids = s.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        output = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
        "        acc.update(preds=output, labels=label)\n",
        "        if i > 1000:\n",
        "            break\n",
        "        i += 1\n",
        "    return(acc.get()[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkcW6GyeT2IA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#learning rate warmup을 위한 준비 \n",
        "step_size = batch_size \n",
        "num_train_examples = len(data_train)\n",
        "num_train_steps = int(num_train_examples / step_size * num_epochs)\n",
        "warmup_ratio = 0.1\n",
        "num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
        "step_num = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mJ3Pw_VT2IH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "9bd064ae-94aa-484e-bc85-657144f5aa8d"
      },
      "source": [
        "for epoch_id in range(num_epochs):\n",
        "    metric.reset()\n",
        "    step_loss = 0\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(train_dataloader):\n",
        "        step_num += 1\n",
        "        if step_num < num_warmup_steps:\n",
        "            new_lr = lr * step_num / num_warmup_steps\n",
        "        else:\n",
        "            offset = (step_num - num_warmup_steps) * lr / (\n",
        "                num_train_steps - num_warmup_steps)\n",
        "            new_lr = lr - offset\n",
        "        trainer.set_learning_rate(new_lr)\n",
        "        with mx.autograd.record():\n",
        "            # load data to GPU\n",
        "            token_ids = token_ids.as_in_context(ctx)\n",
        "            valid_length = valid_length.as_in_context(ctx)\n",
        "            segment_ids = segment_ids.as_in_context(ctx)\n",
        "            label = label.as_in_context(ctx)\n",
        "\n",
        "            # forward computation\n",
        "            out = model(token_ids, segment_ids, valid_length.astype('float32'))\n",
        "            ls = loss_function(out, label).mean()\n",
        "\n",
        "        # backward computation\n",
        "        ls.backward()\n",
        "        trainer.allreduce_grads()\n",
        "        nlp.utils.clip_grad_global_norm(params, 1)\n",
        "        trainer.update(token_ids.shape[0])\n",
        "\n",
        "        step_loss += ls.asscalar()\n",
        "        metric.update([label], [out])\n",
        "        if (batch_id + 1) % (50) == 0:\n",
        "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.10f}, acc={:.3f}'\n",
        "                         .format(epoch_id + 1, batch_id + 1, len(train_dataloader),\n",
        "                                 step_loss / log_interval,\n",
        "                                 trainer.learning_rate, metric.get()[1]))\n",
        "            step_loss = 0\n",
        "    test_acc = evaluate_accuracy(model, test_dataloader, ctx)\n",
        "    print('Test Acc : {}'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1 Batch 50/9375] loss=8.7709, lr=0.0000006667, acc=0.505\n",
            "[Epoch 1 Batch 100/9375] loss=8.5914, lr=0.0000013333, acc=0.526\n",
            "[Epoch 1 Batch 150/9375] loss=8.3027, lr=0.0000020000, acc=0.555\n",
            "[Epoch 1 Batch 200/9375] loss=7.6643, lr=0.0000026667, acc=0.579\n",
            "[Epoch 1 Batch 250/9375] loss=7.4951, lr=0.0000033333, acc=0.603\n",
            "[Epoch 1 Batch 300/9375] loss=7.2966, lr=0.0000040000, acc=0.620\n",
            "[Epoch 1 Batch 350/9375] loss=7.2736, lr=0.0000046667, acc=0.632\n",
            "[Epoch 1 Batch 400/9375] loss=7.0332, lr=0.0000053333, acc=0.641\n",
            "[Epoch 1 Batch 450/9375] loss=7.3415, lr=0.0000060000, acc=0.647\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}